---
title: "Optimal split-plot Designs with R"
author: "Andrea Geistanger, Sebastian Hoffmeister"
date: "`r format(Sys.time(), '%d %B %Y')`"
bibliography: bibliography.bib
output: 
  pdf_document: 
    keep_tex: yes
    toc: yes
geometry: margin=3cm
header-includes:
  \usepackage{float}
  \floatplacement{figure}{H}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo=TRUE,
  message = FALSE,
  warning = FALSE,
  fig.pos="H"  
)

library(rospd)
library(knitr)
library(ggpubr)
```

# Abstract

# Introduction

Split-plot designs are a very well known quantity in the field of Design of Experiments (DoE). First introduced by Fisher @Fisher1992, today they are a standard tool in many applications of DoE and well supported by most statistical software packages. Split-plot designs are the answer to the problem of experimental factors that are hard to change. A factor is hard to change when it is very expensive or time-intensive to change the factor's settings from one level to another. 

Naturally, split-plot designs have been the first thought of the authors when working with a sample preperation robot in the pharmaceutical application of optimizing an assay. Sample preperation robots allow to perform many experiments completly automatically. One restriction is to not use too many different solvents in the process as there is not enough space on the robot to place many different bottles with solvents. In the given application the experimentors are able to place five different bottles of solvents on the robot. Whenever a sixth solvent is supposed to be used the robot has to be stopped and the operator has to manually exchange the bottles of solvents. While this sounds like a typicall hard to change factor there is a major difference: For traditional hard to change factors we try to minimize the number of changes in factor levels. Instead of minimizing the overall number of changes, in this scenario we want to build blocks of experiments in which only a subset of all possible factor levels are used. The problem could be interpreted as generating a blocked design that includes a restriction for each block to use not more than five different solvents.

This paper discusses the problem in more detail. An algorithm to generate optimal designs for this problem is proposed and some resulting designs are evaluated in comparison to completly randomized designs and split-plot designs.

The experienced DoE-expert might skip chapter [1][Restricted Randomization in Split-Plot Designs] which gives a short description of split-plot designs and the typical way of analyzing them. Chapter [2][Less Restrictive Randomization] describes a scenario that the authors where facing that is somewhat in between of a completly randomized design and a split-plot design. In chapter [3][An Extended Algorithm to Generate Optimal Designs with Restricted Randomization] we explain the algorithm used in the rospd-package for the R-software that was developed to create optimal designs for the use case of the previous chapter. A short tutorial on how to use the package follows in chapter [4][Using the rospd-Package]. A comparison of multiple design classes in terms of aliasing and predictive quality is done in chapter [5][Design Evaluation] before we conclude with a summary and an overview of future work (chapter [6][Conclusion and Future Work]).

# Restricted Randomization in Split-Plot Designs

When applying design of experiments (DoE) in the real world it is often difficult to follow one of the core concepts of DoE: Randomization. In a completely randomized design treatments (combinations of factor levels) are performed in complete random order to avoid bias in the analysis due to uncontrolled factors. In many applications following this idea is a problem. Often there are restrictions to the experimental setup that make a complete randomized design extremely expensive or inconvenient at best. 

Kowalski @kowalski:recsplitplot discusses a example for this problem. When trying to optimize the quality of a printing process there are three factors to look at:

- **Blanket Type:** Two possibles types of blankets for the printing press.
- **Cylinder Gap:** The distance between the two cylinders of the printing press.
- **Press Speed:** The speed of the printing press.

![Printing Press Scheme](img/Printing Press.png){ width=200px}

It is fairly simple to change the *Cyliner Gap* or *Press Speed* from one experiment to the next one, as these factors can be reset during the printing process. Exchanging the *Blanket Type* though is much more work. It requires the printing press to be stopped before the old blanket can be removed and the new one can be put on the press. Thus a completely randomized design, like the following one, is very time intensive as it involves exchanging the blanket quite often.

```{r crd_printing_press, echo=FALSE, message=FALSE, warning=FALSE}

  load(file="designs/introcrd.rda")
  kable(intro.crd[[1]]@design.table, caption= "Completely Randomized Design")

```

The reader should be aware that the operator is expected to exchange the blanket after each run even if consecutive runs are using the same type of blanket. The rationale behind that is, that ordinary least squares regression - that is typically used to analyze DoE-data - assumes independence of observations. Using the same blanket for multiple runs would violate this assumption as the experiments done with the same blanket would be correlated with each other.

@Fisher1992 first wrote about that problem and gave a solution with **split-plot Designs**. A split-plot design allows a restricted randomization. For the current example this means that it is no longer necessary to exchange the blanket for each experiment. Instead the same blanket can be used inside of each **whole plot**. 

```{r sp_printing_press, echo=FALSE, message=FALSE, warning=FALSE}
 
  load(file="designs/introsplitplot.rda")

  kable(cbind( Whole_Plots = as.character(c(1,1,2,2,3,3,4,4)),
               intro.splitplot[[1]]@design.table), caption="split-plot Design")
```

In this example the factor **blanket type** would be called a **hard-to-change**-factor (HTC). It is inconvenient to reset this factor for each experiment and thus a restriction to the randomiztion of the experiment is imposed. The restriction limits the number of resets of the hard-to-change factor to a practical amount. 

In contrast to the hard-to-change-factor, all other factors - that can be reset for each experiment without a lot of effort - are called **easy-to-change**-factors (ETC). A split-plot design is still randomized inside of the whole plots so that the easy-to-change-factors are changing as much as possible. 

There are many forms of split-plot designs or rather of hard-to-change factors. @jones:whyandhow, @jones:book and Kowalski @kowalski:recsplitplot give some nice examples on this topic.

Using a restricted randomization in a DoE has several implications:

## Design Model

The **design model** of a split-plot design is different to the traditional design models of completely randomized designs (CRD). For the analysis of CRDs an ordinary least squares regression is applicable:

$$Y = X \beta + \epsilon$$
where:

- $Y$ is a $n \times 1$-vector containing the measured responses. Here $n$ represents the number of runs in the design.
- $\beta$ is a $p\times 1$-vector containing the model parameters. Here $p$ is the number of parameters in the model including the intercept.
- $X$ is the $n \times p$-model matrix, where each column represents one model effect and each of the $n$ rows represent one run of the design.
- $\epsilon$ is a $n \times 1$-vector representing the residuals of the model. The residuals are assumed to be identically, independently and normally distributed with mean 0 and standard deviation $\sigma$.

As mentioned before there is a problem with the assumption of independence of residuals when using a split-plot design. The design is set up so that some factor settings are not changed for a group of experiments. Thus all experiments in one whole plot are correlated with each other. This correlation arrises because the experimentator is missing the variability that is introduced to the process by changing the hard-to-change-factor. To account for the correlation structure in the analysis, split-plot designs are usually analyzed by using mixed models of the following structure:

$$ Y = X\beta + Z\gamma + \epsilon$$
Here $Y$, $X$ and $\beta$ are the same like before.

- $Z$ is a $n \times b$-matrix representing the whole plot structure of the design. $b$ is the number of hard-to-change-factors.
- $\gamma$ is a $b \times 1$ vector representing the variability between different whole plots. Is is assumed that $\gamma  \sim N(0, \sigma_w^2 )$.

The variance-covariance matrix of the response vector Y can be written as (Jones @jones:whyandhow):

$$V = \sigma^2 I_n + \sigma^2_w ZZ'$$

$V$ is a block diagonal matrix, where each block represents one whole plot. $\sigma^2$ is the residual variance, while $\sigma^2_w$ represents the variance between whole plots. A more in depth description of the analysis of split-plot designs is given at Jones @jones:whyandhow or at NÃ¦s @analysisofsplitplots.

## Design Setup

As the design of experiments goes hand in hand with the model one needs to estimate using a different design model has some implication on the planning. While some programs still provide split-plot-variants for classical full- and fractional-factorial designs (Jones @jones:whyandhow), optimal designs have proven their value with a much higher flexibility (Jones & Goos @jones:optimalalg, @jones:book). 

When planning optimal split-plot designs there are two major factors to be considered: 

1. How many whole-plots should be chosen?
2. How to calculate the chosen optimality criterion considering the different type of analysis that is done for split-plot designs?

The number of whole plots is how often the experimentor is willing to reset the condition of the corresponding hard-to-change-factor. The choice of how many whole-plots can be done is often an economical one. On the other hand the number of whole plots is very relevant for the estimation of the random-effects part of the design model and for the power of the model in terms of hard-to-change-factors (see JMP Help @JMPHELP:numberwholepots). The minimal number of whole plots is $l+1$ where $l$ is the number of levels of the hard-to-change-factor. Using only $l$ whole plots would make it impossible to differentiate between the effect of the hard-to-change-factor and the whole plot-effect (which is the variability that comes from resetting the condition of the hard-to-change factor).

The second aspect that is relevant when working with optimal split-plot-designs are the necessary adjustments to optimality criteria. As most optimality criteria depend on the chosen design model it is necessary to adjust them to the new design model including the random effects. Jones and Goos @jones:optimalalg, @jones:ianddoptimal as well as Hooks et al. @hooks:optimalityrandomeffects give an overview of how to calculate different optimality criteria in the presence of random effects:

- **D-Optimality:** $D(X) = |X'V^{-1}X|$ with $X$ being the design matrix and $V$ being the variance-covariance matrix of the response as it was defined above. $V$ depends on $Z$ which is the whole-plot-structutre of the design and on the ratio of $\sigma^2$ and $\sigma^2_w$.
- **I-Optimality:** $I(X) = \text{ average prediction variance } = 2^{-N} tr[(X'V^{-1}X)^{-1}B]$ where $B=\int_{x \in [-1,+1]^N}f(x)f'(x)dx$ is called the moments matrix for the experimental region $\chi = [-1,+1]^N$. $N$ is the number of factors. 
- **A-Optimality:** $A(X) = trace(X'V^{-1}X)$.

# Less Restrictive Randomization

split-plot structure using HTC- and ETC-factors is not always flexible enough to represent all real world problems. The following example comes from an assay development. A crucial part of many assays is the sample preparation. Sample preperation cleans the sample (blood serum, plasma or urine for example) from undesired components like fats or proteins. Getting rid of those parts of the sample helps in terms of reproducibility and lowers the limit of quantification. For optimizing the sample preparation workflows sample preparation robots are often used in laboratories. These robots allow to test a lot of different workflows in a reasonable time. This way it might be possible to test hundreds of different workflows over night. 

Typical DOEs for finding a optimal sample preparation workflow might include factors like *pH*-values, *incubation times*, *incubation temperatures*, usage of different *types of solutions*, etc. The authors where facing a problem with the different *types of solutions* in a workflow optimization DOE. For the optimization 6 different types of solutions shall be tested. These solutions will be put on the robot in bottles. The robot will automatically pick the right solution for any given experiment. But only 4 different bottles can be stored on the robot due to space limitations.

Thus it is possible to work with 4 different solutions and have a completely randomized design - even though one might argue that using always the same bottles of solutions is a violation of the assumption of independence. The latter is ignored for the moment as we can very well assume that the product quality of the solutions is very stable. The robot can work with four solutions completely independently. When the 5th solution is used in the DOE it becomes more complicated. Now the robot has to be stopped and the operator will exchange one or more bottles before the robot is able to continue it's work. 

This is very inconvenient because it makes it impossible to perform experiments over night without having an operator supervising the robot at all time. A completley randomized DOE might lead to a workflow like the following:

```{r, echo=FALSE, message=FALSE, fig.pos="H"}

  kable(
    list(
      data.frame(
        Run = c("1","2","3","4","5","","6","7","8","9", ""),
        Solution = c("A", "B", "A", "C", "D", "Change Bottles", "E", "A", "B", "C", "Change Bottles")
      ),
      data.frame(
        Run = c("10","11","12","13","","14","15","16", "17", "18", "..."),
        Solution = c("D", "E", "A", "B","Change Bottles", "C", "D", "D", "C", "A","...")
      )
      ), 
    row.names = FALSE,
    caption="Completly Randomized Design", format="latex", booktabs=T)


```

Especially for larger DOEs using a completly randomized design would be very inconvenient. It removes most of the benefits that come from automated experimentation as a lot of user interaction with the robot is required. Treating the factor *type of solution* as a HTC-factor would be an alternative.

```{r, echo=FALSE, message=FALSE}

  kable(
    list(
      data.frame(
        Run = c("1","2","3","4","", "5","6","7","8", ""),
        "Whole Plot" = c("1","1","1","1", "" ,"2","2","2","2",""),
        Solution = c("A", "A", "A", "A", "Change Bottles", "C", "C", "C", "C", "Change Bottles")
      ),
      data.frame(
        Run = c("9", "10","11","12","", "13","14","15","16", "..."),
        "Whole Plot" = c("3", "3", "3", "3", "", "4", "4", "4", "4", ""),
        Solution = c("D", "D", "D", "D","Change Bottles", "B", "B", "B", "B","...")
      )
      ), 
    row.names = FALSE,
    caption="split-plot Design", format="latex", booktabs=T)


```

Following this approach we can reduce the work for the operator but there are two problems:

1. **Randomization:** Split-plot designs are always a nod to practicality but all split-plot designs restrict the randomization of the DOE. This makes split-plots vulnerable to effects due to non-controlled factors. For the given use case it would be possible to use a better randomization than a split-plot-design even though the design cannot be completely randomized.

2. **Correlation structure:** One advantage of split-plot-designs is that a correlation between experiments inside of one whole plot is accepted. For the given use case this structure does not really fit the problem. Rather than stopping the robot after each whole plot it would be much more desireable to stop the robot after the fourth whole plot is finished. Thus the correlation structure is different than it would be assumed by the split-plot-design-setup.

A better structured design for the given problem would look like this:

![Design Structure](img/Semi Split plot Structure.png){ width=125px}

All runs are grouped similarly like in a split-plot-design. The restriction to randomization is different though. In a split-plot-design there is at least one hard-to-change-factor that is hold constant in each whole plot. Now there is one factor - we will call it semi-hard-to-change - that is not fixed to one level inside of each whole plot. Instead the factor levels can change from one run to the next. But rather than using any of the possible factor levels, the randomization only allows to use four out of the six possible factor levels in each group.

It would not be wrong to think about this setup as a design using random blocks. Each random block contains experiments that can be performed without operator interaction. What is different to typical designs is a restriction being applied to each random block. This restriction ensures that only a given number of different settings of the SHTC-factor are used inside of each block.

# An Extended Algorithm to Generate Optimal Designs with Restricted Randomization

There is a wide variety of algorithms to produce optimal designs. The Fedorov algorithm (Miller & Nguyen @fedorovalg) is probably one of the more popular ones. JMP as an example for a commercial DOE software uses an coordinate-exchange algorithm (Meyer and Nachtsheim @coordexchange). The R-package rospd uses a modified version of Jone's and Goos' @jones:optimalalg candidate-set-free algorithm to create (D-) optimal split-plot designs. The algorithm and the modifications are described in the following.

## Prerequisites

To use the algorithm the following information has to be provided:

- **Factors: ** For each factors of the design the type (continuous, categorical), factor levels and if it is easy-, hard- or semi-hard-to-change need to be specified. 
- **Whole-Plot-Structure:** If there are any hard- or semi-hard-to-change-factors (SHTC) a matrix representing the whole plot structure needs to be defined. This matrix characterizes how often and when each HTC- or SHTC-factor are changed.
- **SHTC-Group-Size:** This integer defines how many different settings of a SHTC-factor can be used in one whole plot.
- **Number of runs:** How many experiments can be done. 
- **Constraints:** Possible constraints to the factors space need to be defined as a functions.
- **Optimality Criterion**


## Initial Random Design

The algorithm starts by generating a random initial design table. The design table is a data frame containing one combination of factor settings for each run of the design. The initial design uses random factor levels for each cell in the data table. It respects all restrictions like restrictions to the randomization and constraints to the factor space. This includes a possible SHTC-structure as well.

For the given example the initial random design might look like this:

```{r intial_random_design, echo=FALSE}

 # Initial starting design
  initDesign <- GenerateNewDoeDesign(
    factors = list(
      new("doeFactor", name="solvent", levels=c("A", "B", "C", "D", "E", "F"), type="categorical", changes="semi.hard", semi.htc.group.size=as.integer(4)),
      new("doeFactor", name="pH", levels=c(3,12), type="continuous", changes="easy"),
      new("doeFactor", name="time", levels=c(10, 20), type="continuous", changes="easy")
    ),
    design.model = ~solvent+pH+time,
    number.runs = as.integer(20),
    whole.plot.structure = data.frame(solvent=rep(1:4, each=5)),
    optimality.function = DOptimality,
    random.doe = TRUE
  )

  kable(list(cbind(run=1:10, 
              head(initDesign@design.table, 10)), 
        cbind(run=11:20,
              tail(initDesign@design.table, 10))),
        row.names = FALSE, 
        caption= "Initial Random Design", format="latex", booktabs=T)
  
```

## Updating the design

The algorithm starts with a random initial design and updates cells of that design table sequentially to improve the optimality of the design. Therefore an iteration matrix is generated. The iteration matrix specifies in which order the elements of the design are updated.

```{r iteration_matrix, echo=FALSE}
 
  colnames(initDesign@iteration.table) = c("solvent", "pH", "time")

  kable(
    list(
      head(initDesign@iteration.table, 10),
      tail(initDesign@iteration.table, 10)
      ), 
    row.names = FALSE,
    caption="Iteration Matrix", format="latex", booktabs=T)

```

Each index number in the iteration matrix represents one update step. In the first step all cells of the design table are updated for which the iteration matrix equals 1. In the current example this is the first whole plot of the factor solvent. The second step updates the first row of the factor pH, the second step updates the second row of the factor pH and so on.

The iteration matrix is structured in a way to first update all cells in the first whole plot. The first whole plot is defined by the factor that is hardest to change - that is the factor with the smallest number of changes. Inside of each whole plot the algorithm updates each cell beginning with HTC- and SHTC-factors ordered by the number of changes from few changes to many changes. ETC-factors are updated last.

The updating works differently depending on the type of the factor:

- **ETC-Factors** are updated one cell at a time. Each possible level for that factor is considered. For continuous factors the user has to specify how many intervals between minimum and maximum factor level will be considered. If replacing the current value in the design table with any of the other possible values improves the optimality of the design, the best value is used. 
- **HTC-Factors:** are updated in groups. Each possible value is considered. Instead of updating just one cell all cells of the current whole plot in the design table are replaced simultaneously with the same value. The value that grants the best optimality for the design is used.
- **SHTC-Factors** are updated in groups defined by the whole plots. Other than for HTC-factors the values for each cell in one whole plot can be different. All possible settings are tested and the best one in terms of the chosen optimality is used.

Updating a SHTC-factor is laborious. Looking at the first whole plot of the current example there are many possible factor settings. The restriction of the design is to not use more than four of the six possible solvents in one whole plot. There are $\frac{m!}{(m-k)!} = \frac{6!}{(6-4)!} = 15$ possible combinations to pick four solvents out of the six. 

Here the parameters $m$ and $k$ are:

- $m$: the overall number of levels of the SHTC-factor
- $k$: the number of different levels that can be used in one whole plot.

For each of the 15 sets of solvents there are $m^{n_w} = 4^5 = 1024$ possible combinations with $n_w$ being the size of the whole plot. Thus it requires calculating the optimality of $15*1024=15360$ designs to determine the best settings for the SHTC-factor *solvent* just for the first whole plot.

Respecting this issue a faster but less comprehensive way of updating SHTC-factors was implemented. Here all elements of one whole plot are updated individually. This is the same approach that is used for ETC-factors with the exception that not all possible factor levels are used but rather a subset defined by the number of possible settings inside of one whole plot. 

To address this issue by default a less comprehensive approach to determine the optimal settings for each SHTC-factor is used. This approach treats the SHTC-factor just like a ETC-factor 

By default the algorithm will use one random start and update each element of the design table up to 25 times. At the end of each step the algorithm if any cell of the desing was updated. If no changes where made to the design the algorithm converged and stops.

# Using the rospd-Package

The rospd-package (**R O**ptimal **S**plit **P**lot **D**esigns) is an implementation of the previously described algorithm. This chapter shows how to use the package function to create optimal (semi-)split-plot designs. The core part of the package are the two classes *doeFactor* and *doeDesign*. The *doeDesign* class collects all information required to generate an optimal design. This includes a list of *doeFactors* that should be investigated in the DoE. 

## The doeFactor class

Objects of class *doeFactor* represent factors in the DoE. *doeFactor* is a S4 class with the following slots:

- **name:** The name of the factor as a character.
- **type:** Either *"continuous"* or *"categorical"*. Continuous factors are numeric factors that could theoretically take any real number in a given range. Categorical factors use either character or numeric values. They are interpreted as nominal variables.
- **levels:** For continuous factors a vector containing the minimum and maximum factor level needs to be specified as numerics. For categorical factors a vector with all possible factor levels - either numeric or characters - is required.
- **number.levels:** The number of levels is only required for continuous factors. This integer represents how many different levels are used during the design generation. E.g. for $number.levels = 3$ and $levels=c(100, 300)$ the factor levels that are used during the design updating are 100, 200 and 300. For $number.levels = 5$ and $levels=c(100, 300)$ the possible factor levels are 100, 150, 200, 250 and 300. The number of levels have a strong impact on the runtime of the algorithm.
- **changes:** This defines if a factor is *"easy"*-, *"hard"*- or *"semi.hard"*-to-change.
- **semi.htc.group.size:** This is only required for SHTC-factors. This integer defines how many different factor levels can be used inside of one whole plot.

The factors of the current example can be declared the following way:

```{r factor_definition}

# pH - an ETC continuous factor
phFactor <- new("doeFactor",
                name="pH",
                type="continuous",
                levels = c(3,12),
                number.levels = as.integer(2),
                changes="easy"
                )
phFactor

# time - an ETC continuous factor
timeFactor <- new("doeFactor",
                name="time",
                type="continuous",
                levels = c(10,20),
                number.levels = as.integer(2),
                changes="easy"
                )
timeFactor

# solvent - a SHTC categorical factor
solventFactor <- new("doeFactor",
                     name="solvent",
                     type="categorical",
                     levels=c("A", "B", "C", "D", "E", "F"),
                     changes="semi.hard",
                     semi.htc.group.size=as.integer(4)
                     )
solventFactor
```

## The doeDesign class

The *doeDesign*-class is the heart of rospd. It stores all information required to generate an optimal design and will contain the final design table afterwards as well. This way any *doeDesign*-object can serve as a documentation of how the design was created. Like the *doeFactor*-class *doeDesign* is an S4-class. As it uses a lot of different slots only the required ones will be discussed here.

- **factors:** A list of all factors that are used in the DoE as objects of class *doeFactor*. This list may have only one item.
- **whole.plot.structure:** The whole plot structure is a data.frame representing when changes can be made for all HTC- and SHTC-factor. This data.frame needs to contain one column for each HTC- and SHTC-factor using the factor names as column names. The whole plots of each factor are represented by index numbers starting at 1 for each factor.
- **number.runs:** The number of experiments as *integer*.
- **design.model:** The design model as a *formula*. The formula is supposed to contain only the fixed effects part of the model as the random effects part is already defined by the **whole.plot.structure**.
- **optimality.function:** a *function* that can be used to calculate the optimality of a given design. The algorithm will use the *doeDesign*-object as the only argument of the function. Making use of the slots **design.matrix**, **design.model** and **variance.ratio** of the class **doeDesign** should allow to calculate most optimality criteria. The rospd package provides predefined functions to calculate <span style="color:red">DOptimality(), IOptimality() and AOptimality()  TODO: Does it?</span>. The functions are a wrapper of the C-implementations of the skpr-package @skprpkg.
- **variance.ratio :** The expected ratio of $\sigma^2$ (residual variance) and $\sigma^2_w$ (between whole plot variance). This is used for the calculation of some optimality criteria. By default a variance ratio of 1 is used.

There is a function **GenerateNewDoEDesign** that should be used to initialize a new *doeDesign*-object. A *doeDesign*-object for the current example might look like this:

```{r doe_specification}

  doeSpecification <- GenerateNewDoeDesign(
      factors = list(solventFactor, phFactor, timeFactor),
      whole.plot.structure = data.frame(solvent=rep(1:6, each=10)),
      number.runs = as.integer(60),
      design.model = ~solvent+pH+time,
      optimality.function = DOptimality
  )
```

## Generating Optimal Designs

The function **GenerateOptimalDesign** generates an optimal design for the given specification. The function uses the following arguments:

- **doeSpec:** The doe specification as an object of class *doeDesign*.
- **random.start:** This argument controls how many different random starting designs are used. The default setting is 1. The function will return a list of one doeDesign for each random start. These designs will be sorted from best to worst in terms of their optimality.
- **max.iter:** The maximum number of iterations. One iterations updates all cells of the design table once. 

```{r generate_optimal_design, eval=FALSE}

  optimalDesign <- GenerateOptimalDesign(doeSpecification, 
                                         random.start = 1,
                                         max.iter = 10,
                                         silent=TRUE)
```

```{r loadOptimalDesign, echo=FALSE}

  load(file="designs/optimalDesign.rda")

  wp.and.doe <- data.frame("WholePlot" = optimalDesign[[1]]@whole.plot.structure, 
             optimalDesign[[1]]@design.table)

  colnames(wp.and.doe) <- c("whole plot", "solvent", "pH", "time")
  
  kable(list(
          head(wp.and.doe, 15),
          tail(wp.and.doe, 15, addrownums=FALSE)
        ), 
        caption = "Subset of the Optimal Design", 
        format="latex", 
        booktabs=T)

```

# Design Evaluation

## Sample Preperation Robot Example

In this section we want to evaluate the quality of the generated design. For that purpose we will compare it with three alternative designs: 

- one **completely randomized design** (CRD)
- a standard **split-plot** design using 12 whole plots each of size 5.
- a standard **split-plot** design using 8 whole plot. To end up with 60 runs 4 of the whole plots use size 7 and 4 of the whole plots are of size 8.

The rationale here is to have the CRD as the best case scenario. As the CRD does not include any restrictions on randomization and assumes completely independents runs it will always have the best statistical properties. Of course it would not be possible to do this design in reality. 

The split-plot design with 12 whole plots is not that realistic as well, as it involves much more interactions of the operator with the machine than we would like to do - twelve instead of only 6 for our design. The split-plot with eight whole plots is more realistic but on the lower end in terms of the number of whole plots.

```{r generateAlternativeDesigns, results=FALSE, echo=FALSE}
  
  load(file="designs/crd.rda")
  load(file="designs/splitplot1.rda")
  load(file="designs/splitplot2.rda")

```

Lets start by having a look at the distribution of factor solvent for each of the designs.

```{r distributionSolvent, echo=FALSE, message=FALSE, fig.width=7, fig.height=2.5}

shtc <- data.frame(doe=rep("SHTC", 60), solvent=optimalDesign[[1]]@design.table$solvent)
crd1 <- data.frame(doe=rep("CRD", 60), solvent=crd[[1]]@design.table$solvent)
sp1 <- data.frame(doe=rep("Split-Plot 12 Whole Plots", 60), solvent=splitplot1[[1]]@design.table$solvent)
sp2 <- data.frame(doe=rep("Split-Plot 8 Whole Plots", 60), solvent=splitplot2[[1]]@design.table$solvent)

allSolvents <- rbind(crd1, shtc, sp2, sp1)

ggplot(allSolvents, aes(x=solvent)) + geom_bar(fill="white", color="black") + facet_grid(~doe)

```

The CRD, the semi-split-plot and the split-plot design using 12 whole plots are prefectly balanced. For the split-plot design using eight whole plots it is not possible to achieve balance for the solvent factor.

```{r aliasingHeatMap, results=FALSE, echo=FALSE, fig.width=6, fig.height=6}
  multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
    library(grid)
  
    # Make a list from the ... arguments and plotlist
    plots <- c(list(...), plotlist)
  
    numPlots = length(plots)
  
    # If layout is NULL, then use 'cols' to determine layout
    if (is.null(layout)) {
      # Make the panel
      # ncol: Number of columns of plots
      # nrow: Number of rows needed, calculated from # of cols
      layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                      ncol = cols, nrow = ceiling(numPlots/cols))
    }
  
   if (numPlots==1) {
      print(plots[[1]])
  
    } else {
      # Set up the page
      grid.newpage()
      pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
  
      # Make each plot, in the correct location
      for (i in 1:numPlots) {
        # Get the i,j matrix positions of the regions that contain this subplot
        matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
  
        print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                        layout.pos.col = matchidx$col))
      }
    }
  }

  p1 <- AliasingHeatMap(crd[[1]]) + labs(title="CRD") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  p2 <- AliasingHeatMap(optimalDesign[[1]], includeWholePlots = TRUE) + labs(title="Semi Split-Plot") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  p3 <- AliasingHeatMap(splitplot1[[1]], includeWholePlots = TRUE) + labs(title="Split-plot 12 Whole Plots") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  tmp <- AliasingHeatMap(splitplot2[[1]], includeWholePlots = TRUE) + labs(title="Split-plot 8 Whole Plots") + theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))
  
  heatmapLegend <- get_legend(tmp)
  p4 <- tmp + theme(legend.position = "none")
  
  multiplot(p1,p2,p3,p4, cols=2)
  
```

```{r aliasingHeatMapLegend, results=FALSE, echo=FALSE, fig.width=2.25, fig.height=1}
  as_ggplot(heatmapLegend)
```

The aliasing heatmaps show that there are only minor differences when comparing the designs by their inter-factor correlations. All designs show some correlation between the effects of the different solvents. The split-plot design with 8 whole plots shows a little less homogeneous correlation structure of the solvent effects. This comes from imposing the very strict restrictions to randomization.


The whole plot - called *wp_solvent* in the graph - in case of the semi split-plot design has much lower correlation with the solvent effects compared to the traditional split-plot designs.

```{r fdsPlots, echo=FALSE, results=FALSE, fig.width=7, fig.height=4, cache=TRUE, fig.align="center"}

  tmp.spv <- spv(10000,
     design=list(         
                 crd[[1]]@design.table,
                 optimalDesign[[1]]@design.table,
                 splitplot1[[1]]@design.table,
                 splitplot2[[1]]@design.table
                 ),
     type="lhs",
     formula = crd[[1]]@design.model,
     unscaled=TRUE)
  
  names(tmp.spv) <- c("CRD", 
                      "Semi split-plot", 
                      "Split-Plot - 12 Whole Plots", 
                      "Split-Plot - 8 Whole Plots")

  plot(tmp.spv, which="fds")

```

The FDS-plot shows that the traditional split-plot designs with 8 whole plots performs slightly worse than the other designs in terms of prediction variance. All other designs show equal prediction variance. Thus we see only one line in the plot.

## Required Number of Whole Plots

The previous evaluation shows that split-plot designs with SHTC-factors are not worse in terms of statistical quality than CRDs or traditional split-plots with a sufficient number of whole plots. When dealing with HTC-factors the number of whole plots is often the critical parameter. As SHTC-factors allow much more flexibility compared to true HTC-factors we are able to reduce the required number of whole plots for the given example. 

In traditional split-plot designs the required number of whole plots depends first of all on the number of HTC-factor levels. There needs to be at least one addition wholeplot to be able to estimate the factor effects and the between whole plot variation.

For SHTC-factors this is much less of a problem, as variation inside of the whole plots is possible. Thus the minimum number of whole plots is only depending on the overall number of factor levels and the number of factor levels that can be used inside of one whole plot. All factor levels have to be used at least once. At the same time the correlation of whole plots and all other factors should be minimized to be able to estimate the model effects with high precision.

In the following we compare semi split-plot designs for the previous example with varying number of whole plots.

```{r distributionSolventsWholePlots, results=FALSE, echo=FALSE, fig.width=6, fig.height=2.5}

  load("designs/semi2wp.rda")
  load("designs/semi3wp.rda")
  load("designs/semi4wp.rda")
  load("designs/semi6wp.rda")

  tbl <- data.frame(
    solvent = c(
      as.character(optimalDesign2wp[[1]]@design.table$solvent),
      as.character(optimalDesign3wp[[1]]@design.table$solvent),
      as.character(optimalDesign4wp[[1]]@design.table$solvent),
      as.character(optimalDesign6wp[[1]]@design.table$solvent)
    ),
    doe = c(rep("2 Whole Plots", 60), 
            rep("3 Whole Plots", 60), 
            rep("4 Whole Plots", 60),
            rep("6 Whole Plots", 60))
  )
  
  ggplot(tbl, aes(x=solvent)) + geom_bar(fill="white", color="black") + facet_grid(~doe)
  
```

Especially when working with only two wholeplots the algorithm does not find a solution granting perfect balance in terms of the SHTC-factor. This problem is less severe when using three whole plots instead of just two. That statement is only true for the given example. In general the minimum number of whole plots to achieve perfect balance and minimize correlation of whole plots and the SHTC-factor depends on the size of the whole plots and on the number of possible levels in each whole plot. 

**TODO: Kann man kombinatorisch herleiten wie viele Whole Plots man bracht bei gegebener Whole Plot GrÃ¶Ãe und SHTC-Group-Size?**

```{r solventDistribution2WP, results=FALSE, echo=FALSE, fig.width=7, fig.height=3.5}

  
  tmp.tbl <- data.frame(
    `Whole Plot` = factor(optimalDesign2wp[[1]]@whole.plot.structure$solvent),
    solvent = optimalDesign2wp[[1]]@design.table$solvent
  )

  tmp.tbl2 <- data.frame(
     `Whole Plot` = factor(optimalDesign3wp[[1]]@whole.plot.structure$solvent),
     solvent = optimalDesign3wp[[1]]@design.table$solvent
   )

  p1 <- ggplot(tmp.tbl, aes(x=solvent, fill=Whole.Plot)) + geom_bar(color="black") + theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5)) + guides(fill = guide_legend(title = "Whole Plot", title.position = "top", title.hjust=.5))

  p2 <- ggplot(tmp.tbl2, aes(x=solvent, fill=Whole.Plot)) + geom_bar(color="black") + theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))+ guides(fill = guide_legend(title = "Whole Plot", title.position = "top", title.hjust=.5)) + ylab("")


  multiplot(p1, p2, cols=2)
  
```

The design with two whole plots shows some correlation of solvent effects and the whole plot. This correlation is reduced with every additional whole plot introduced. Going from two whole plots to three whole plots reduces the correlation a lot. All further additions do not change the correlation much. This is not a problem as the three whole plot design shows very low correlations anyways.

```{r heatmaps2, results=FALSE, echo=FALSE, fig.width=6, fig.height=6}
  p1 <- AliasingHeatMap(optimalDesign2wp[[1]], includeWholePlots = TRUE) + labs(title="2 Whole Plots") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  p2 <- AliasingHeatMap(optimalDesign3wp[[1]], includeWholePlots = TRUE) + labs(title="3 Whole Plots") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  p3 <- AliasingHeatMap(optimalDesign4wp[[1]], includeWholePlots = TRUE) + labs(title="4 Whole Plots") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  p4 <- AliasingHeatMap(optimalDesign6wp[[1]], includeWholePlots = TRUE) + labs(title="6 Whole Plots") + theme(legend.position="none", plot.title = element_text(hjust = 0.5))
  
  multiplot(p1,p2,p3,p4, cols=2)
```

# Conclusion and Future Work

We presented an algorithm to generate optimal split-plot designs with the inclusion of SHTC-factors. We could show that these designs can be of comparable quality like CRDs or in the worst case still as good as traditional split-plot designs. 

For the described use case this is a great relieve. In this case using a CRD is no alternative as we would not be able to make use of the automatization of the process. Traditional split-plot designs could be done, but are still not desireable as they require still a relatively large number of whole plots. With the proposed approach we are able to minimize the amount of manual work and still approximate the qualities of a CRD.

Currently the rospd-package is only available on Githup **(???-> wollen wir das? momentan nur im Roche-Github)** and will be published on CRAN in the future **(??? -> wollen wir das?)**. The current implementation is done mostly in R and the performance could be improved by changing to a C-implementation.

# References

---
nocite: |
  @jones:optimalalg, @jones:ianddoptimal, @hooks:optimalityrandomeffects, @hardin:optimalg
...